{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vtc_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f0e48c9b52f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvtc_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChoi_k2c2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vtc_model'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate singer technique embeddings and metadata for training\n",
    "(metadata consists of tuples(speaker directory path, speaker embeddings, spectrogram file paths)\n",
    "\"\"\"\n",
    "\n",
    "import pickle, pdb, os, random, yaml\n",
    "from vtc_model import Choi_k2c2\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_dir = '/homes/bdoc3/my_data'\n",
    "\n",
    "model = 'NoAttnLayerAutoVcSpecSpmelNormalizedLatentDim256'\n",
    "model_path = '/homes/bdoc3/phonDet/results'\n",
    "\n",
    "ckpt = '100Epoch_checkpoint.pth.tar'\n",
    "ckpt_path = os.path.join(model_path, model, ckpt)\n",
    "\n",
    "config_file = 'config_params.pkl'\n",
    "\n",
    "spmel_dir = '/homes/bdoc3/my_data/phonDet/spmel_desilenced_normalized/spmel_params.yaml'\n",
    "\n",
    "config_path = os.path.join(model_path, model, config_file)\n",
    "config = pickle.load(open(config_path, 'rb'))\n",
    "\n",
    "with open(spmel_dir) as File:\n",
    "    spmel_params = yaml.load(File, Loader=yaml.FullLoader)\n",
    "\n",
    "cuda_num = 1\n",
    "device = f'cuda:{cuda_num}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_layer1.0.weight\n",
      "conv_layer1.0.bias\n",
      "conv_layer1.1.weight\n",
      "conv_layer1.1.bias\n",
      "conv_layer1.1.running_mean\n",
      "conv_layer1.1.running_var\n",
      "conv_layer1.1.num_batches_tracked\n",
      "conv_layer2.0.weight\n",
      "conv_layer2.0.bias\n",
      "conv_layer2.1.weight\n",
      "conv_layer2.1.bias\n",
      "conv_layer2.1.running_mean\n",
      "conv_layer2.1.running_var\n",
      "conv_layer2.1.num_batches_tracked\n",
      "conv_layer3.0.weight\n",
      "conv_layer3.0.bias\n",
      "conv_layer3.1.weight\n",
      "conv_layer3.1.bias\n",
      "conv_layer3.1.running_mean\n",
      "conv_layer3.1.running_var\n",
      "conv_layer3.1.num_batches_tracked\n",
      "conv_layer4.0.weight\n",
      "conv_layer4.0.bias\n",
      "conv_layer4.1.weight\n",
      "conv_layer4.1.bias\n",
      "conv_layer4.1.running_mean\n",
      "conv_layer4.1.running_var\n",
      "conv_layer4.1.num_batches_tracked\n",
      "fc_layer1.0.weight\n",
      "fc_layer1.0.bias\n",
      "fc_layer1.2.weight\n",
      "fc_layer1.2.bias\n",
      "fc_layer1.2.running_mean\n",
      "fc_layer1.2.running_var\n",
      "fc_layer1.2.num_batches_tracked\n",
      "fc_layer2.0.weight\n",
      "fc_layer2.0.bias\n",
      "fc_layer2.1.weight\n",
      "fc_layer2.1.bias\n",
      "fc_layer2.1.running_mean\n",
      "fc_layer2.1.running_var\n",
      "fc_layer2.1.num_batches_tracked\n",
      "fc_layer3.0.weight\n",
      "fc_layer3.0.bias\n",
      "fc_layer3.1.weight\n",
      "fc_layer3.1.bias\n",
      "fc_layer3.1.running_mean\n",
      "fc_layer3.1.running_var\n",
      "fc_layer3.1.num_batches_tracked\n",
      "lstm.weight_ih_l0\n",
      "lstm.weight_hh_l0\n",
      "lstm.bias_ih_l0\n",
      "lstm.bias_hh_l0\n",
      "lstm.weight_ih_l0_reverse\n",
      "lstm.weight_hh_l0_reverse\n",
      "lstm.bias_ih_l0_reverse\n",
      "lstm.bias_hh_l0_reverse\n",
      "lstm.weight_ih_l1\n",
      "lstm.weight_hh_l1\n",
      "lstm.bias_ih_l1\n",
      "lstm.bias_hh_l1\n",
      "lstm.weight_ih_l1_reverse\n",
      "lstm.weight_hh_l1_reverse\n",
      "lstm.bias_ih_l1_reverse\n",
      "lstm.bias_hh_l1_reverse\n",
      "feat2weight_ffnn.weight\n",
      "feat2weight_ffnn.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtc = Choi_k2c2(config, spmel_params).eval().cuda()\n",
    "\n",
    "# pretrained autovc model loaded into G model\n",
    "vtc_optimizer = torch.optim.Adam(vtc.parameters(), 0.0001)\n",
    "vtc_checkpoint = torch.load(ckpt_path)\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for key, val in vtc_checkpoint['model_state_dict'].items():\n",
    "    if key.startswith('class_layer'):\n",
    "        continue\n",
    "    print(key)\n",
    "    new_state_dict[key] = val \n",
    "vtc.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtc.load_state_dict(vtc_checkpoint['model_state_dict'])\n",
    "vtc_optimizer.load_state_dict(vtc_checkpoint['optimizer_state_dict'])\n",
    "\n",
    "for state in vtc_optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.cuda(cuda_num)\n",
    "\n",
    "vtc.to(device)\n",
    "vtc.eval()\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fft_size': 1024, 'fmin': 90, 'hop_size': 256, 'n_mels': 96, 'sr': 22050}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spmel_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvautovc",
   "language": "python",
   "name": "venvautovc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
